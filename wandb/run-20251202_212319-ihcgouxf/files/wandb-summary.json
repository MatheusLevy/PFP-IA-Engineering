{"_step":1,"_runtime":58,"status":"failed","_wandb":{"runtime":58},"error_message":"Caught AcceleratorError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/matheus/Documents/PFP-IA-Engineering/.venv/lib/python3.14/site-packages/torch/utils/data/_utils/pin_memory.py\", line 34, in do_one_step\n    data = pin_memory(data, device)\n  File \"/home/matheus/Documents/PFP-IA-Engineering/.venv/lib/python3.14/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n    {k: pin_memory(sample, device) for k, sample in data.items()}\n        ~~~~~~~~~~^^^^^^^^^^^^^^^^\n  File \"/home/matheus/Documents/PFP-IA-Engineering/.venv/lib/python3.14/site-packages/torch/utils/data/_utils/pin_memory.py\", line 57, in pin_memory\n    return data.pin_memory(device)\n           ~~~~~~~~~~~~~~~^^^^^^^^\ntorch.AcceleratorError: CUDA error: out of memory\nSearch for `cudaErrorMemoryAllocation' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n","stage":"general_error","trial_number":0,"error_type":"AcceleratorError","_timestamp":1.764721461866461e+09}